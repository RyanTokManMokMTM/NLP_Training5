{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0Uk+g1voIGkVBoisCtibg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanTokManMokMTM/NLP_Training5/blob/main/translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPS3wst0OjMv",
        "outputId": "8d4dc178-4b09-49e8-b0a5-c77b304355ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkF9KiaYVacP",
        "outputId": "be6e53e0-aa21-4574-881d-a0dff2ae1e21"
      },
      "source": [
        "!unzip /content/gdrive/MyDrive/translation2019zh.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/translation2019zh.zip\n",
            "  inflating: translation2019zh_train.json  \n",
            "  inflating: translation2019zh_valid.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P__VVu6haZIC"
      },
      "source": [
        "# read json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOC5EB_kb_ah",
        "outputId": "0efe2ee3-ed1f-4e51-a9fe-15b8ac2c7f2e"
      },
      "source": [
        "!pip install opencc"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (765 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 39.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 194 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 256 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 266 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 317 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 327 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 337 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 378 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 389 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 399 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 409 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 440 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 450 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 460 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 471 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 501 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 512 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 522 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 532 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 542 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 563 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 573 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 583 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 593 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 604 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 614 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 634 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 645 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 655 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 665 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 675 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 686 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 706 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 716 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 727 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 737 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 747 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 757 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 765 kB 36.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: opencc\n",
            "Successfully installed opencc-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6azpMrgta0mz"
      },
      "source": [
        "import json\n",
        "import opencc\n",
        "train_data = []\n",
        "\n",
        "chineseCc = opencc.OpenCC('s2hk.json')\n",
        "with open(\"translation2019zh_train.json\",newline=\"\") as js:\n",
        "  for i in js:\n",
        "    data = json.loads(i)\n",
        "    data[\"english\"] = chineseCc.convert(data[\"english\"])\n",
        "    data[\"chinese\"] = chineseCc.convert(data[\"chinese\"])\n",
        "    train_data.append(data)\n",
        "  js.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGW0o4M4Vat_"
      },
      "source": [
        "train_input = []\n",
        "train_output = []\n",
        "input_chars = set()\n",
        "ouput_chars = set()\n",
        "\n",
        "for data in train_data:\n",
        "  input = data[\"english\"]\n",
        "  output = data[\"chinese\"] #add \\t for begin and \\n for the end\n",
        "  output = \"\\t\" + output + \"\\n\"\n",
        "  train_input.append(input)\n",
        "  train_output.append(output)\n",
        "  #save each character to a set\n",
        "  for char in input: # english material is include Chinese！？？\n",
        "    if char not in input_chars:\n",
        "      input_chars.add(char)\n",
        "\n",
        "  for char in output:\n",
        "    if char not in ouput_chars:\n",
        "      ouput_chars.add(char)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblCcEL8ggBA"
      },
      "source": [
        "input_chars = sorted(list(input_chars))\n",
        "ouput_chars = sorted(list(ouput_chars))\n",
        "\n",
        "#number of encoder and decoder\n",
        "num_encoder_tk = len(input_chars)\n",
        "num_decoder_tk = len(ouput_chars)\n",
        "\n",
        "#max encoder and decoder length\n",
        "max_encoder_length = max([len(txt) for txt in train_input]) #get the maxinum txt in input list\n",
        "max_decoder_length = max([len(txt) for txt in train_output]) #get the maxinum txt in output list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HZP3I3yjBcm"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OiTTWRfjHq4"
      },
      "source": [
        "#mapping tk and index\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,LSTM,Dense\n",
        "\n",
        "input_tk_index = dict([(char,i) for i,char in enumerate(input_chars)])\n",
        "output_tk_index = dict([(char,i) for i,char in enumerate(ouput_chars)])\n",
        "\n",
        "#make shape using np.zero as 3d shape\n",
        "encoder_input_dt = np.zeros((len(train_input),max_encoder_length,num_encoder_tk),dtype=\"float32\")\n",
        "decoder_input_dt = np.zeros((len(train_input),max_decoder_length,num_decoder_tk),dtype=\"float32\")\n",
        "decoder_output_dt = np.zeros((len(train_input),max_decoder_length,num_decoder_tk),dtype=\"float32\")\n",
        "\n",
        "#change to vector 3d\n",
        "for i ,(train_input,train_output) in enumerate(zip(train_input,train_output)):\n",
        "  for t,char in enumerate(train_input):\n",
        "    #only z-index has value = 1\n",
        "    encoder_input_dt[i,t,input_tk_index[char]]  = 1\n",
        "  for t,char in enumerate(train_output):\n",
        "    #only z-index has value = 1\n",
        "    decoder_input_dt[i,t,output_tk_index[char]]  = 1\n",
        "    if t > 0:\n",
        "      decoder_output_dt[i,t-1,output_tk_index[char]] = 1\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ESTKbm-neIz"
      },
      "source": [
        "#content\n",
        "encoder_inputs = Input(shape=(None,num_encoder_tk))\n",
        "\n",
        "#return last state output as decoder input\n",
        "encoder_lstm = LSTM((latent_dim),return_state=True)\n",
        "\n",
        "#lstm return output\n",
        "encoder_output,state_history,state_current = encoder_lstm(encoder_inputs)\n",
        "\n",
        "#keep the state only\n",
        "encoder_states = [state_history,state_current]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdpZ4X8yo0WC"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOKC6JFMo2ZS"
      },
      "source": [
        "decoder_inputs = Input(shape=(None,num_decoder_tk))\n",
        "decoder_lstm = LSTM((latent_dim),return_sequences=True,return_state=True)\n",
        "decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
        "\n",
        "#full connected layer\n",
        "decoder_dense = Dense(num_decoder_tk,activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Define a model\n",
        "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMq5mD7Pp81J"
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\")\n",
        "\n",
        "#model optimizsm\n",
        "model.fit([encoder_input_dt,decoder_input_dt],decoder_output_dt,batch_size=64,epochs=100,validation_split=0.2)\n",
        "\n",
        "#save model\n",
        "model.save(\"seq2seq.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}